\documentclass{article}

\title{Mehrabi et al. 2020. The global divide in data driven farming. Supplementary Information B: Global farm size map.}
\author{Code by Vincent Ricciardi}
\usepackage[margin=2.5 cm]{geometry}
\usepackage{color}
\usepackage[parfill]{parskip}
\usepackage{lineno}
\usepackage{hyperref}
\usepackage{subfig}
\usepackage{float}
%\usepackage{tgadventor} % fonts
%\renewcommand{\familydefault}{\sfdefault}
\usepackage[backend=bibtex, style=ieee, citestyle=authoryear]{biblatex}
\addbibresource{ReferencesDDA_SIC.bib}
\addbibresource{Rpackages.bib}

% \input{ReferencesPapersTex} 
%creates ReferencesDDA_SIC.bib

\begin{document}

<<bibbackground, echo=F, include=F>>=
Sys.setenv(TEXINPUTS = getwd(),
           BIBINPUTS = getwd(),
           BSTINPUTS = getwd())
@


<<knitrOpts, echo=F, include=F>>=
require(knitr)
require(printr)
require(formatR)
require(renv)
opts_chunk$set(concordance  = TRUE,
               fig.align    = 'center',
               fig.pos      = 'H',  # no floating
               crop         = hook_pdfcrop,
               comment      = NA,
               message      = FALSE,
               warning      = FALSE,
               error        = FALSE,
               cache        = FALSE,
               width.cutoff = 60)

options(digits = 3)
@

\maketitle

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Aim of document}

The aim of this document is to create a global map of farm sizes. We do this by merging two currently available sources of information on the distribution of farm sizes across the world: national level data on farm size distributions and subnational data on field size distributions. The resulting map is a "best guess" of where different sizes of farms are distributed globally. We caution that this map should not be used for detailed country level analysis, but is intended for global assessment studies, where results are typically aggregated at the regional or global level. This document explains the underlying data, pre-processing, and algorithm we developed to create this map. We were driven to create this map as a work that can be built upon and improved as higher resolution and more accurate data become available.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Reproducibility}
\label{reproducibility}

Here we call the  \textbf{R} package \texttt{renv} (\cite{R-renv}). This will create a local library on your computer and install a copy of the packages required by this project as they existed on CRAN by the specified version number, and update the \textbf{R} session to use these packages. This helps make our analysis fully reproducible on your machine. 

Note, the `renv.lock` file needs to be in the top level of this project's directory. This code block needs to only be run when initially setting up your project then can be commented out.

<<reproducibility, echo=T, include=T>>=
# Uncomment during first run
# install.packages('renv')
# renv::init()
@

We also set the seed of the entire document to ensure the same results when randomly sampling.

<<setseed>>=
set.seed(123)
@


Note that the \textbf{R} version used here is \Sexpr{substring(text = version$version.string, first = 11, last = 28)}.

%%%%%%%%%%%%%%%%%%%%%%%%

<<echo=F, include=F>>=
packages <- c('data.table',
              'foreach',
              'formatR',
              'ggthemes',
              'gmodels',
              'hablar',
              'leaflet',
              'lintr',
              'magrittr',
              'knitr',
              'kknn',
              'plyr',
              'raster',
              'renv',
              'reshape2',
              'rgdal',
              'rworldmap',
              'sf', # devtools::install_github("r-spatial/sf",force=T)
              'tidyverse',
              'viridis',
              'zoo')

# Installs required packages not currently installed
new_packages <- packages[!(packages %in% installed.packages()[,'Package'])]
if(length(new_packages)) install.packages(new_packages)

lapply(packages, require, character = TRUE)
detach(package:plyr)  # detached here to avoid conflicts with dplyr
@


<<echo=F, include=F>>=
c <- paste0('R-', packages)
c <- paste0('\\Sexpr{',c,'}', ' (\\cite{', c,'})')
# Writes R packages used to .bib.
# Commented out b/c I need to manually fix syntax on an erroneous an entry
# write_bib(x = packages, file = 'Rpackages.bib')
@
 
For the analysis in this document we will be using the following packages: \Sexpr{c}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data}

In this analysis we leverage two key datasets. \cite{Lowder} (Lowder, hereafter) contains farm size distributions (in terms of agricultural area and the number of farms) for ~100 countries. \cite{Lesiv} (Lesiv, hereafter) contains a crowd-sourced point data of categorical field size classes (ranging from very small to large fields). We use Lesiv's qualitative field size classes to spatially disaggregate the Lowder farm size classes. Links and access dates to these input data and other ancillary data sets used in our analysis as highlighted below:

1. Global field size data from Lesiv, retrieved from from http://pure.iiasa.ac.at/id/eprint/15526/ on October 12th, 2018.

2. Country farm size distributions from Lowder, retrieved from 
http://iopscience.iop.org/article/10.1088/1748-9326/11/12/124010 on July 12th, 2018.

3. Global cropland and pastureland from \cite{Ramankutty} (Ramankutty, hereafter), retrieved from www.earthstat.org on July 12th 2018.

4. Country boundaries, retrieved internally in R through \cite{R-rworldmap}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Country boundaries}

First we make a raster of the world country data from the \texttt{rworldmap} package.
<<countryraster>>=
world  <- rworldmap::getMap(resolution = 'low')
lookup <- as.data.frame(cbind(as.character(
  world@data[,'ISO3']),
  world@data[,'ADMIN'],
  as.character(world@data[,'ADMIN'])))

raster.world <- raster(res = c(0.0833282, 0.0833282))
extent(raster.world) <- extent(world)
world.raster <- rasterize(as(world, 'SpatialPolygons'), 
                          raster.world,
                          field = world@data[, 'ADMIN'],
                          fun   = 'first')
world.rast <- writeRaster(world.raster, 
                          'data/tmp/worldrast.tif', 
                          format    = 'GTiff', 
                          overwrite = TRUE)

world  <- raster('data/tmp/worldrast.tif')
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Country farm size distributions}

Lowder's data contains two variables at the national level, the amount of agricultural area per farm size class, and the number of farms per farm size class. We are interested in the amount of agricultural area per farm size class for our analysis. This data is distributed as the World Census of Agriculture's (WCA) farm size classes, which are: 0-1 ha, 1-2 ha, 2-5 ha, 5-10 ha, 10-20 ha, 20-50 ha, 50-100 ha, 100-200 ha, 200-500 ha, 500-1000 ha, \>1000 ha. This data is read in here and columns relabeled.

<<readlowder>>=
# Load Lowder's distribution dataset
lwd <- read.csv('data/lowder/Lowder_2016_dist.csv', 
                header = T, 
                na.strings = c('','NA'))

# Subset only agricultural area
lwd <- lwd[which(lwd$Holdings..agricultural.area != 'Holdings'), ]
lwd <- lwd[, c(1,5:15)]
names(lwd) <- c('country', '0_1', '1_2', '2_5', 
                '5_10', '10_20', '20_50', '50_100', '100_200', 
                '200_500', '500_1000', '1000_5000')

# Ensure variable type is numeric
for (i in names(lwd)[2:length(names(lwd))]) {
  lwd[[i]] <- as.numeric(lwd[[i]])
}
@

Next we need to calculate the cumulative sum per country across Lowder's farm size classes.  To do this we first convert the data from wide to long format, and set classes for countries without data to zero area.

<<lwdlong>>=
lwd <- melt(lwd, id.vars = c('country'))
lwd[is.na(lwd)] <- 0
@

Then we calculate the proportional agricultural area for each farm size class for each country. We note that Lowder contains some countries without farm size distributions and some countries do not have a distribution for each farm size class, and so we remove those cases here.

<<lwdpercent>>=
lwd <- lwd %>% 
  group_by(country) %>% 
  mutate(total = sum(value),
         perc = value / total) %>%
   filter(value > 0) %>%
  select(country, variable, perc)
@

Finally, cast dataframe back into wide form.
<<lwdwide>>=
lwd <- dcast(lwd, country ~ variable)
write.csv(lwd, 'data/tmp/lwd.csv')
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Global agricultural area}

We use Ramankutty's 10 km\textsuperscript{2} cropland map (crop, hereafter) and pastureland map (pasture, hereafter) as our reference layer of the distribution of agricultural land at the subnational level.  We read in these files here and unionize the crop and pasture maps to create an agricultural land raster (ag, hereafter).

<<getagland>>=
crop <- paste0('data/Ramankutty_2008_cropland/',
                'CroplandPastureArea2000_Geotiff/',
                'cropland2000_area.tif')

pasture <- paste0('data/Ramankutty_2008_cropland/',
                  'CroplandPastureArea2000_Geotiff/',
                  'pasture2000_area.tif')

crop <- raster(crop)
pasture <- raster(pasture)

# Here we take a union of crop and pasture areas
# Set NA to 0, ensure same origin, find sum 
crop_tmp <- crop
pasture_tmp <- pasture
crop_tmp[is.na(crop_tmp)] <- 0
pasture_tmp[is.na(pasture_tmp)] <- 0
origin(crop_tmp) <- origin(pasture_tmp) <- c(0.0, 0.0)
ag <-mosaic(crop_tmp, pasture_tmp, fun = sum)
ag[ag[] == 0] <- NA 
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Global field sizes}

Here we interpolate the crowd-sourced field size data point data onto Ramankutty's agricultural area data. While the original sampling frame for this field size was on a unionized cropland map, we extend the distribution here in an attempt to better match and account for the inclusion of non-cropland in Lowder's farm size data (noting that later we will clip the resulting product to cropland only).  We use kk-nearest neighbor (kkNN) on a 0.01 degree grid (kkNN is a weighted variant of kNN that we use to try to account as best as possible for Lesiv's sparsely sampled points in Africa).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Read in Data}

First, we read in the estimated dominant field sizes point data and subset to not include NA values or values coded as having no fields.
<<getlesiv>>=
fs <- read.csv("data/Fritz_2019/Global Field Sizes/estimated_dominant_field_sizes.csv")
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Pre-process Data}

We recode Lesiv's data according to their coding as detailed below. And then convert this data into a spatial object.

\begin{itemize}
  \item 3502 - Very large fields with an area of greater than 100 ha
  \item 3503 - Large fields with an area between 16 ha and 100 ha
  \item 3504 - Medium fields with an area between 2.56 ha and 16 ha
  \item 3505 - Small fields with an area between 0.64 ha and 2.56 ha
  \item 3506 - Very small fields with an area less than 0.64 ha
  \item 3507 - no fields
  \item NA - skipped
\end{itemize}

<<recodelesiv>>=
fs[which(fs$field_size == 3507), 5] <- NA

fs_clean <- fs %>%
  na.omit() %>%
  dplyr::mutate(field_size_fac = as.factor(field_size)) %>%
  dplyr::mutate(fs_verbatim_fac = recode(field_size_fac,
                                         "3502" = "very large",
                                         "3503" = "large",
                                         "3504" = "medium",
                                         "3505" = "small",
                                         "3506" = "very small"))%>%
  dplyr::select(-rowid,-sampelid) %>%
  st_as_sf(coords = c("x", "y"),
           crs = "+proj=longlat +ellps=WGS84")
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Interpolate}

We make a target raster grid to interpolate onto using the agricultural area raster. We use a very simple method of interpolation based on the latitude and longitude. 

<<binarize>>=
ag_GR0 <- ag
ag_GR0[] <- ifelse(ag_GR0[] > 0, 1, NA)
target_pts <- rasterToPoints(ag, spatial = TRUE)
target_pts_agGR0 <- rasterToPoints(ag_GR0, spatial = TRUE)
@

We then train the kkNN model using different types of kernels and number of points used in the classification procedure. We use 10 fold cross validation to identify the best parameters to use in the final model (noting that CV does not approximate the test error as would be estimated using an independent hold-out set).

<<trainlesiv>>=
fs_train <- data.frame(field_size = fs_clean$fs_verbatim_fac,
                       x = st_coordinates(fs_clean)[,1],
                       y = st_coordinates(fs_clean)[,2])

fs_interp_train <- kknn::train.kknn(field_size ~.,
                                    data = fs_train,
                                    ks = seq(5,51, 5),
                                    distance = 2,
                                    kernel = c("gaussian",
                                               "triangular",
                                               "rectangular",
                                               "epanechnikov",
                                               "optimal"),
                                    kcv = 10)
@

Next we summarize and plot the results of the model fitting. We note the the minimal classifications error is \Sexpr{min(fs_interp_train$MISCLASS)}. Crudely, with 5 classes we would expect a raw misclassification error of 80\%, which suggests the model has in the best case helped reduce blind uncertainty by around \Sexpr{(min(fs_interp_train$MISCLASS)/.8)*100}\%. We also plot the error from the different models below. 

Future versions improvements to this model may be made through identifying ancillary features that do a better job of predicting field size classes than simply latitude and longitude alone. Similarly, using an ordinal response, instead of the nominal response defaulted here, is likely to improve predictions also.

<<plotknnres, fig.cap='kkNN results of field size interpolation', out.width='0.6\\linewidth', fig.height=5, fig.width=5,size='footnotesize', echo=F>>=
par(mfrow = c(1, 1))
plot(fs_interp_train)
@

We use the best fitting model parameters to predict the field size classes across the agricultural area grid, and then extract the fitted values and the associated probabilities.
<<predicted>>=
fs_interp_final <- kknn::kknn(field_size ~ .,
                              train = fs_train,
                              test = target_pts_agGR0,
                              kernel = fs_interp_train$best.parameters$kernel,
                              k = fs_interp_train$best.parameters$k)

target_pts_agGR0_res <- target_pts_agGR0 %>%
  # extract the interpolated class at each
  # grid cell with the kknn::fitted function
  as.data.frame() %>%
  # only retain the probability of the
  # interpolated size class, discard the others
  mutate(field_size_fit = fitted(fs_interp_final),
         prob = apply(fs_interp_final$prob, 1, function(input) max(input)))
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Rasterize}

Here we convert results back to a raster and save the results of the fitted classes.

<<rasterize>>=
target_pts_agGR0_res_spdf <- target_pts_agGR0_res
coordinates(target_pts_agGR0_res_spdf) <- ~ x + y

fs_interp_final_ras <- rasterize(target_pts_agGR0_res_spdf,
                                 ag,
                                 as.integer(
                                 target_pts_agGR0_res_spdf$field_size_fit),
                                 progress = "text")

fs_interp_final_ras_prob <- rasterize(target_pts_agGR0_res_spdf,
                                      ag,
                                      target_pts_agGR0_res_spdf$prob,
                                      progress = "text")

lesiv <- fs_interp_final_ras
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Create common dataframe}

To run our algorithm to create a field size map we need to ensure all rasterized datasets (i.e., field size, crop, pasture, ag, and country boundaries) are all in the same resolution, have the same coordinate reference system (crs), and have the same spatial extent, which we do in this section.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Convert to equal area}

Here we set each dataset to have an equal area (Eckert IV) at a 8.4 km\textsuperscript{2} resolution. To interpolate, we use nearest neighbor for the categorical data and bilinear for the continuous data.

<<setcrs>>=
rast.list.ngb <- list(lesiv, world)
rast.list.bil <- list(crop, pasture, ag)

resValue <- 8439
rast.list.ngb.eq <- lapply(rast.list.ngb, function(x)
  projectRaster(
    x,
    res    = c(resValue, resValue),
    crs    = '+proj=eck4 +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0',
    method = 'ngb',
    over   = T))

rast.list.bil.eq <- lapply(rast.list.bil, function(x)
  projectRaster(
    x, 
    res    = c(resValue, resValue),
    crs    = '+proj=eck4 +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0',
    method = 'bilinear',
    over   = TRUE))

rast.list <- c(rast.list.ngb.eq, rast.list.bil.eq)  # Combine data
names(rast.list) <- c('lesiv', 'world', 'crop', 'pasture', 'ag')
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Set extents}

Next, we need to make sure that all the rasters have the same spatial extents. The country boundaries include Antarctica, while the cropland/pastureland/ag and field size data do not (e.g., crop ymin is -8501789, while the country boundaries ymin is -8503388). To ensure all the datasets match we need to expand the cropland/pastureland/ag and Lesiv extents to match the country boundaries extent. This means extending the cropland/pastureland/ag and Lesiv data to also include the country boundary grid cells; we do this by adding rows of NA grid cells.

<<setextent>>=
ex1 <- extent(rast.list$world)

# Extend
rast.list.ex <- lapply(rast.list,    
                       function(x) extend(x, ex1))
# Crop
rast.list.c  <- lapply(rast.list.ex, 
                       function(x) crop(x, ex1))
# Force equal extent
rast.list.et <- lapply(rast.list.c,  
                       function(x) setExtent(x, ex1,
                                             keepres = TRUE))
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Create stack}
Now that all the layers' resolution, crs, and spatial extent are equal, we can create a raster stack and proceed with the analysis.

<<stack>>=
rast.all <- stack(rast.list.et)
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Finalize data set}

We now convert the data in the raster stack into a dataframe, which we will use for later analysis.

<<getrasterdat>>=
df <- raster::extract(rast.all, 1:ncell(rast.all), df = T)
df <- as.data.frame(df)
df$ID <- 1:nrow(df)
@

Set any crop, pasture value under 0.01 to NA, to account for sparse agricultural areas.
<<thresholdagland>>=
df$crop <- ifelse(df$crop >= 0.01, df$crop, NA)
df$pasture <- ifelse(df$pasture >= 0.01, df$pasture, NA)
df$ag <- ifelse(df$ag >= 0.01, df$ag, NA)
@

Next we add back in the country names (presently they are only country ISO3 IDs), then subset the data to only contain countries in the Lowder dataset (this speeds up processing).
<<countrynames>>=
world  <- getMap(resolution = 'low')
lookup <- as.data.frame(
  cbind(
    as.character(world@data[,'ISO3']),
    world@data[,'ADMIN'],
    as.character(world@data[,'ADMIN'])))

matched    <- lookup[match(df$world, lookup$V2), ]
df$ISO3    <- matched[[1]]
df$country <- matched[[3]]
@

We then match Lowder's country names to the global country boundary country names.
<<matcountryname>>=
countries <- data.frame(names = sort(unique(df$country)))
lwdNames  <- data.frame(names = unique(lwd$country))
lwdNames$names  <- str_trim(lwdNames$names)
lwdNames$indata <- lwdNames$names %in% unique(countries$name)

# List of names in lowder that do not match dataset's names
# note Guadeloupe, Martinique, Reunion has no data
# lwdNames[which(lwdNames$indata == FALSE), ]

changeFrom <- c('Korea Rep. of', 
                "Lao People's Democratic Republic",
                'Viet Nam',
                'Serbia',
                'Bahamas',
                'Venezuela (Bolivarian Republic of)',
                'St. Kitts & Nevis',
                'Iran (Islamic Republic of)',
                "Côte d'Ivoire",
                'Virgin Islands United States')
                
changeTo   <- c('South Korea',
                'Laos',
                'Vietnam',
                'Republic of Serbia',
                'The Bahamas',
                'Venezuela',
                'Saint Kitts and Nevis',
                'Iran',
                'Ivory Coast',
                'United States Virgin Islands')

require(plyr)
lwd$country <- mapvalues(str_trim(lwd$country),
                         from = changeFrom,
                         to   = changeTo)
detach('package:plyr')
@

Subset the dataset to only the countries containing farm size distributions.
<<subsetdat>>=
lwdNames <- unique(lwd$country)
df_lwd <- df[which(df$country %in% lwdNames), ]
df_not_lwd <- df[which(!df$country %in% lwdNames), ]
@

<<echo=F, include=F>>=
# Here is tmp code to figure out how many countries and percent crop area we would be missing if we only used lowders' countries.

# tmp <- df
# tmp$area <- df$crop * resValue^2 * 0.0001
# 
# View(tmp %>% 
#      mutate(tot = sum(area, na.rm = T)) %>%
#      group_by(country) %>% 
#      summarise(c_tot = round(sum(area, na.rm = T) / max(tot, na.rm = T), 3)))
# 
# l  <- sum(df_lwd$crop * resValue^2 * 0.0001, na.rm = T)
# nl <- sum(df_not_lwd$crop * resValue^2 * 0.0001, na.rm = T)
# 
# # percent of area not in lowder
# nl / (l + nl)
# 
# # number of countries not/in lowder
# length(sort(unique(df_not_lwd$country)))
# length(sort(unique(df_lwd$country)))
# 
# require(sp)
# tmp <- data.frame(NAME = unique(df_not_lwd$country))
# tmp$check <- 1
# world  <- getMap(resolution = 'low')
# world <- merge(world, tmp, by = 'NAME')
# world@data$color <- ifelse(world@data$check == 1, '#fefcd7', '#8382ff')
# # Create a color palette for the map:
# 
# require(leaflet)
# # Basic choropleth with leaflet
# m <- leaflet(world) %>% 
#   addTiles()  %>% 
#   setView( lat=10, lng=0 , zoom=2) %>%
#   addPolygons(fillColor = world@data$color, stroke=FALSE,
#               popup = world@data$NAME) %>%
#   addLegend(position = 'topright',
#             colors = c('#fefcd7', '#8382ff'),
#             labels = c('Not in Lowder', 'In Lowder'))
# m
# library(htmlwidgets)
# saveWidget(m, file = 'in_lowder.html')
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Match Field Sizes to Farm Sizes}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Algorithm}

Here are the steps we used to create the farm size map, with uncertainty at the level of the distribution of farm to field size matching. The algorithm makes the assumption that smaller field sizes are owned by smaller farms (although we note that the uncertainty in this assumption grows with farm size, as while smaller farms can not own large fields, large farms can own many small fields).

\begin{enumerate}
  \item Group pixels by country
  \item Assign pseudo-random number to pixels
  \item Reorder the pixels in a nested fashion: first by interpolated field size classes, and then by the pseudo-random numbers
  \item Compute pixel wise agricultural area from Ramankutty 
  \item Compute cumulative agricultural area from Ramankutty 
  \item Divide cumulative sum of agricultural area by total area in each country to get cumulative proportional sums of agricultural area from Ramankutty 
  \item Assign pixel fields sizes to farm size classes by matching the cumulative proportional agricultural area from Lowder to the cumulative proportional agricultural area for interpolated Lesiv product  where pixels are ordered from smallest to largest fields
  \item For countries not in Lowder, hard code farm size based on field sizes.
  \item Convert result to a raster
  \item Save raster
  \item Iterate steps 1 to 10 100x
\end{enumerate}


Steps 1 to 6 are written below.

<<steps1to6>>=
cumsumSkipNA <- function(x) {
    FUNC <- match.fun('cumsum')
    x[!is.na(x)] <- FUNC(x[!is.na(x)])
    return(x)
}

df_lwd$lesiv <- factor(df_lwd$lesiv)
levels(df_lwd$lesiv) <- c('5', '4', '3', '2', '1')
df_lwd$lesiv <- as.integer(as.character(df_lwd$lesiv))


steps_1_6 <- function(df_lwd) {
  
  dat <- df_lwd %>% 
    mutate(pseudorandom = sample(1:n(), n(), replace = F))  %>%
    arrange(country, lesiv, pseudorandom) %>%
    group_by(country) %>%
    mutate(crop = crop * resValue^2 * 0.0001,       # new
           pasture = pasture * resValue^2 * 0.0001, # new
           ag = crop + pasture,                     # new
           ag_area = ag * resValue^2 * 0.0001, # original was this line only
           cumsum_area = cumsumSkipNA(ag_area), 
           prop_sums = cumsum_area / max(cumsum_area, na.rm = T))
  
  return(dat)
}
@

Step 7 is written below.

<<step7>>=
cumsumSkipNA <- function(x) {
    FUNC <- match.fun('cumsum')
    x[!is.na(x)] <- FUNC(x[!is.na(x)])
    return(x)
}

step_7 <- function(dat) {
  
  tmp <- lwd[, 2:length(lwd)]
  tmp <- t(tmp)
  tmp <- apply(tmp, FUN = function(x) cumsumSkipNA(x), MARGIN = 2)
  tmp <- t(tmp)
  tmp <- as.data.frame(tmp)
  tmp$country <- lwd$country
  
  dat <- merge(dat, tmp, by = 'country')
  
  for (x in unique(dat$country)) {
      
      tmp <- dat[which(dat$country == x), ]
      
      tmp$farm <- ifelse(tmp$prop_sums <= tmp$`0_1`
                         & !is.na(tmp$`0_1`),
                         '0_1',
                  ifelse(tmp$prop_sums <= tmp$`1_2` 
                         & !is.na(tmp$`1_2`),
                         '1_2', 
                  ifelse(tmp$prop_sums <= tmp$`2_5` 
                         & !is.na(tmp$`2_5`),
                         '2_5',
                  ifelse(tmp$prop_sums <= tmp$`5_10` 
                         & !is.na(tmp$`5_10`),
                         '5_10',
                  ifelse(tmp$prop_sums <= tmp$`10_20` 
                         & !is.na(tmp$`10_20`),
                         '10_20',
                  ifelse(tmp$prop_sums <= tmp$`20_50`
                         & !is.na(tmp$`20_50`),
                         '20_50',
                  ifelse(tmp$prop_sums <= tmp$`50_100`
                         & !is.na(tmp$`50_100`),
                         '50_100',
                  ifelse(tmp$prop_sums <= tmp$`100_200` 
                         & !is.na(tmp$`100_200`),
                         '100_200',
                  ifelse(tmp$prop_sums <= tmp$`200_500` 
                         & !is.na(tmp$`200_500`),
                         '200_500',
                  ifelse(tmp$prop_sums <= tmp$`500_1000` 
                         & !is.na(tmp$`500_1000`),
                         '500_1000',
                  ifelse(tmp$prop_sums <= tmp$`1000_5000` 
                         & !is.na(tmp$`1000_5000`),
                         '1000_5000', 
                         '1000_5000'
                         )))))))))))
    
      if (x == as.character(unique(dat$country)[1])) {
        out <- tmp
      } else {
        out <- rbind(out, tmp)
      }
  }
  
  out <- out[,c(2,length(out))]
  
  dat <- merge(df, out, 
               by = 'ID', 
               all.x = T, 
               all.y = T)
  
  return(dat)

}
@


Step 8 is written below. For countries not in Lowder, we hard code the farm size matched to that field size class. We take the upper end of the given range and match it to Lesiv's codes (e.g., code 3502 becomes 200 ha)


1  - 3502 - Very large fields with an area of greater than 100 ha  - 100-200 ha

2  - 3503 - Large fields with an area between 16 ha and 100 ha     - 50-100 ha

3  - 3504 - Medium fields with an area between 2.56 ha and 16 ha   - 5-10 ha

4  - 3505 - Small fields with an area between 0.64 ha and 2.56 ha  - 1-2 ha

5  - 3506 - Very small fields with an area less than 0.64 ha       - 0-1 ha

NA - 3507 - no fields;


<<step8>>=
step_8 <- function(dat) {
  
  field_2_farm <- data.frame(
    lesiv = c(1,2,3,4,5),
    # lesiv = c(5,4,3,2,1),
    farm_avg = c('100_200', 
                 '50_100',
                 '5_10',
                 '1_2',
                 '0_1'))
  
  dat <- merge(dat, field_2_farm, by = 'lesiv', all.x = T)
  
  # Make sure that any inf are NA
  dat2 <- dat %>% rationalize()
  
  # Make sure farm and farm_avg cats are same type
  dat$farm <- as.character(dat$farm)
  dat$farm_avg <- as.character(dat$farm_avg)
  
  dat$farm_final <- ifelse(dat$ag >= 0.01 & !is.na(dat$farm), 
                           dat$farm,
                    ifelse(dat$ag >= 0.01 & !is.na(dat$lesiv), 
                           dat$farm_avg, NA))
  return(dat)
}
@

Step 9: Generate farm size raster

<<step9>>=
step_9 <- function(dat, x = 'farm_final') {
  # Places farm size values into a raster
  # Params:
  #   df
  # Return:
  #   raster object
  
  if (x == 'farm_final') {
    dat$rasterValues <- as.numeric(
      str_split_fixed(dat[[x]], '_', 2)[, 2])
  } else {
    dat$rasterValues <- dat[[x]]
  }
  
  # Clip to cropland area
  dat$rasterValues <- ifelse(is.na(dat$crop), NA, dat$rasterValues)
  
  dat <- dat[order(dat$ID), ]
  rast_final <- rast.all@layers[[1]]
  rast_final <- setValues(rast_final, dat$rasterValues, dat$ID)
  
  return(rast_final)
}
@

Step 10: Write raster

<<>>=
step_10 <- function(rast_final, i) {
  # Writes raster
  # Params:
  #   rast_final
  #   i: random number
  # Returns
  #   Writes raster to file
  
  writeRaster(rast_final,
              filename  = paste0(
                'raster_out_forCleanRunTest/farmSize_',
                # 'raster_out_forPublication/farmSize_agarea_',
              format(Sys.time(), "%Y%m%d"), '_', i, '.tif'),
              format    = 'GTiff',
              overwrite = TRUE)
}
@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Resampled Results}


Step 11: Repeat steps 1-10 100x. Note, 100 runs is illustrative. For more stable results increase to > 1k.

<<>>=
# i = 1
# for (i in 1:100) {  # use for full run
for (i in 1:2) {      # use for test run
  dat1 <- steps_1_6(df_lwd)
  dat2 <- step_7(dat1)
  dat3 <- step_8(dat2)
  rast <- step_9(dat3)
  step_10(rast, i)
}
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Sanity Check}

We sanity check that the proportional farm size distributions per country equals Lowder’s. We use one run as an example. As we can see the data is very close to the one-to-one line (but not exactly as would be expected based on small differences in row matching in our algorithm). Since the sampling scheme randomly shuffles the data, this plot will be slightly different for each sample.

<<finalsanitycheck, fig.cap='Sanity check that the summed farm size per country equals Lowders', out.width='0.6\\linewidth', fig.height=5, fig.width=7, size='footnotesize', echo=F>>=
dat1 <- steps_1_6(df_lwd)
dat2 <- step_7(dat1)
dat3 <- step_8(dat2)

# freshly read in lowder
lwd_tmp <- read.csv('data/lowder/Lowder_2016_dist.csv', 
                header = T, 
                na.strings = c('','NA'))

# Subset only agricultural area
lwd_tmp <- lwd_tmp[which(lwd_tmp$Holdings..agricultural.area != 'Holdings'), ]
lwd_tmp <- lwd_tmp[, c(1,5:15)]
names(lwd_tmp) <- c('country', '0_1', '1_2', '2_5', 
                '5_10', '10_20', '20_50', '50_100', '100_200', 
                '200_500', '500_1000', '1000_5000')

# Ensure variable type is numeric
for (i in names(lwd_tmp)[2:length(names(lwd_tmp))]) {
  lwd_tmp[[i]] <- as.numeric(lwd_tmp[[i]])
}

# wide to long
lwd_tmp <- melt(lwd_tmp, id.vars = c('country'))
lwd_tmp[is.na(lwd_tmp)] <- 0

# convert to data table (for faster merge)
lwd_tmp <- as.data.table(lwd_tmp)

# calculate our final map's ag area per farm size class per country
dat3_tmp <- dat3 %>% 
  mutate(area = crop + pasture,
         final = as.numeric(str_split_fixed(farm, '_', 2)[, 2]),
         area =  ag * resValue^2 * 0.0001) %>%
  group_by(country, farm) %>%
  summarise(area = sum(area, na.rm = T))  %>%
  na.omit() %>%
  select(country, farm, area)

# rename columns to match lowder's
names(dat3_tmp) <- names(lwd_tmp)
  
# inner merge our values and lowder's
tmp_compare <- merge(dat3_tmp, lwd_tmp, by = c('country', 'variable'), all.x = F, all.y = F)

# convert to proportional area
tmp_compare <- tmp_compare %>%
  group_by(country) %>%
  mutate(totx = sum(value.x),
         toty = sum(value.y)) %>%
  group_by(country, variable) %>%
  mutate(value.xp = value.x / totx,
         value.yp = value.y / toty)

# compare our data and lowders
tmp_compare$diff <- tmp_compare$value.xp - tmp_compare$value.yp

# plot comparison
ggplot(tmp_compare, aes(value.xp, value.yp)) +
  geom_point() +
  geom_abline(aes(slope = 1, intercept = 0)) +
  guides(color = F) +
  xlab('Our data') +
  ylab("Lowder's data") +
  theme_minimal() +
  ggtitle('Comparing proportional area between Lowder and our data')
@




\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Final Output}

Here is the mode of the 100 farm size maps generated.

<<finalmap, fig.cap='Final map, where dominant farm size (ha) is shown per pixel for the mode of the 100 generated maps.', out.width='0.6\\linewidth', out.width='100%', size='footnotesize', echo=F>>=

knitr::include_graphics('finalMap.png')

# Uncomment to produce map - for knitr compilation
# this causes current computer to push memory caps
# even with gc()
# gc()
# fts <- list.files(path = 'raster_out_forPublication/',
#                  pattern = 'tif$',
#                  full.names = T)
# fs <- stack(fs)
# fs <- brick(fs)
# 
# getmode <- function(v) {
#   uniqv <- unique(v)
#   uniqv[which.max(tabulate(match(v, uniqv)))]
# }
# 
# fs <- calc(fs, getmode)
# fs_spdf <- as(fs, 'SpatialPixelsDataFrame')
# 
# fs_df <- as.data.frame(fs_spdf)
# colnames(fs_df) <- c('value', 'x', 'y')
# fs_df <- fs_df %>%
#   arrange(value) %>%
#   mutate(value = factor(value, unique(value)))
# 
# ggplot() +
#   geom_raster(data = fs_df,
#             aes(x, y,
#                 fill = value),
#             alpha = 0.8) +
#   theme_map(base_family = 'AvantGarde') +
#   theme(plot.background = element_rect(fill = 'black'),
#         legend.position = 'right',
#         legend.justification = 'top',
#         legend.text = element_text(color = 'white'),
#         legend.title = element_text(color = 'white'),
#         legend.background = element_rect(fill = 'transparent')) +
#   # scale_fill_brewer(palette = 'PiYG', direction = -1) +
#   scale_fill_viridis_d(direction = -1, begin = .1) +
#   coord_equal() +
#   labs(fill = 'Dominant\nFarm Size (ha)')

 
# ggsave('finalMap.png', dpi = 800)
@

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Session information}

<<sessionInfo, size='footnotesize'>>= 
sessionInfo()
@ 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\printbibliography[heading=bibintoc]

\end{document}